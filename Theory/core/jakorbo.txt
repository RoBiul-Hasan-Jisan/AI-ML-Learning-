 Regression Algorithms

Used for predicting continuous numeric values.

1. Linear Models

Linear Regression -> done
Simple Regression -> done 

Ridge Regression -> done 

Lasso Regression -> done 

ElasticNet Regression->done 

Bayesian Linear Regression

Polynomial Regression -> done 

Tree-based Models

Decision Tree Regressor ->done 

Random Forest Regressor ->done 

Extra Trees Regressor

Gradient Boosting Regressor (GBR)->done 

XGBoost Regressor -> done 

LightGBM Regressor ->done 

CatBoost Regressor ->done 

3. k-Nearest Neighbors

KNN Regressor

4. Support Vector Machines

SVR (Support Vector Regression)

5. Probabilistic / Statistical Models

ARIMA / SARIMA (time series)

Gaussian Process Regression

Quantile Regression

6. Neural Network Models

Artificial Neural Networks (ANN Regression)

RNN / LSTM / GRU (Regression for time series)

Transformer Regression Models

Classification Algorithms

Used for predicting categories/labels.

1. Linear Models

Logistic Regression

Linear Discriminant Analysis (LDA)

Quadratic Discriminant Analysis (QDA)

2. Tree-based Models

Decision Tree Classifier

Random Forest Classifier

Extra Trees Classifier

Gradient Boosting Classifier

XGBoost Classifier ->done 

LightGBM Classifier ->done 

CatBoost Classifier ->done 

3. Support Vector Machines

SVC (Support Vector Classifier)->done

Linear SVC->done

RBF SVC->done

4. k-Nearest Neighbors

KNN Classifier-done 

5. Bayes Classifiers

Naive Bayes->done 

Gaussian NB

Multinomial NB

Bernoulli NB

Complement NB

6. Ensemble Methods

Bagging Classifier->done

Boosting Classifier->done

AdaBoost->done

Stacking Classifier

Voting Classifier

7. Neural Network Models

Artificial Neural Networks (ANN Classification)

CNN (Image classification)

RNN / LSTM Classification

Transformer-based Classification (e.g., BERT)

Algorithms that handle BOTH (Regression + Classification)

Decision Trees

Random Forest

Gradient Boosting

XGBoost

LightGBM

CatBoost

k-Nearest Neighbors (KNN)

SVM (SVC, SVR)

Neural Networks

Classical Algorithms

(Still asked in exams/interviews)

Perceptron ->done

Adaline / Madaline-done 

Nearest Centroid Classifier-done

Ridge Classifier ->done

Passive Aggressive Classifier ->done 

SGD Classifier / Regressor -> done 










UNSUPERVISED LEARNING ALGORITHMS


Clustering Algorithms

Used for grouping similar data points.

1. Partition-based Models

K-Means Clustering

K-Medoids (PAM)

Mini-Batch K-Means

2. Hierarchical Models

Agglomerative Clustering

Divisive Clustering

Linkage methods:

Single Linkage

Complete Linkage

Average Linkage

Ward’s Method

3. Density-based Models

DBSCAN

HDBSCAN

OPTICS

4. Model-based / Probabilistic Clustering

Gaussian Mixture Models (GMM)

Expectation–Maximization (EM)

5. Graph-based Clustering

Spectral Clustering

Community Detection (Louvain – concept)



Dimensionality Reduction

Used for feature extraction, visualization, noise removal.

  1. Linear Methods

Principal Component Analysis (PCA)

Truncated SVD

Factor Analysis


Independent Component Analysis (ICA)



 2. Non-linear Methods

t-SNE

UMAP

Isomap

Locally Linear Embedding (LLE)

Kernel PCA

3. Neural Network Based

Autoencoders

Variational Autoencoders (VAE)



Anomaly / Outlier Detection

Used for fraud detection, fault detection, rare events.

1. Distance-based Methods

Z-score

IQR Method

kNN-based Outlier Detection

2. Model-based Methods

Isolation Forest

One-Class SVM

Local Outlier Factor (LOF)

Elliptic Envelope



Association Rule Mining

Used for discovering relationships in transactions.

Apriori Algorithm

FP-Growth Algorithm

Metrics

Support

Confidence

Lift

Conviction



Topic Modeling (Text – Unsupervised NLP)
1. Probabilistic Models

Latent Dirichlet Allocation (LDA)

Probabilistic Latent Semantic Analysis (pLSA)

2. Matrix Factorization

Non-negative Matrix Factorization (NMF)

Latent Semantic Analysis (LSA)



 Representation Learning

Used for learning useful embeddings.

Autoencoders

Variational Autoencoders (VAE)

Contrastive Learning (intro level)

Self-Supervised Learning (concept)



Evaluation Metrics (Unsupervised-Specific)
Clustering Evaluation

Silhouette Score

Davies–Bouldin Index

Calinski–Harabasz Index

Dimensionality Reduction

Explained Variance Ratio (PCA)

Reconstruction Error


Algorithms That Bridge Unsupervised → Supervised

(VERY IMPORTANT)

PCA + Classifier

Autoencoder + Classifier

Clustering as feature engineering

Semi-supervised learning (concept)

EXAM 

If you know these well, you’re solid:

K-Means

Hierarchical Clustering

DBSCAN

PCA

GMM

Isolation Forest

t-SNE vs UMAP

LDA (Topic Modeling)