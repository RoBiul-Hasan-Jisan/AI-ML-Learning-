{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a0a2ef",
   "metadata": {},
   "source": [
    "# SVC\n",
    "\n",
    "SVC is like drawing the widest possible street between different classes. It doesn't just separate points - it creates the maximum possible margin between classes.\n",
    "\n",
    "\n",
    "Core Idea: The Widest Street Analogy\n",
    "Imagine you have:\n",
    "\n",
    "Red balls (Class A) on the left\n",
    "\n",
    "Blue balls (Class B) on the right\n",
    "\n",
    "SVC's goal: Draw a street (decision boundary) that:\n",
    "\n",
    "Separates red from blue perfectly (or as well as possible)\n",
    "\n",
    "Makes the street as wide as possible\n",
    "\n",
    "Puts \"guard rails\" (support vectors) at the edges\n",
    "\n",
    "Support Vectors = The data points closest to the boundary that \"support\" the street width\n",
    "\n",
    "How It Actually Works:\n",
    "\n",
    "For Linearly Separable Data:\n",
    "\n",
    "```bash\n",
    "\n",
    "# Simple 2D example\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create some separable data\n",
    "X = np.array([[1, 2], [2, 3], [2, 1], [3, 2],  # Class 0\n",
    "              [6, 5], [7, 6], [7, 4], [8, 5]]) # Class 1\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "# Train SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X, y)\n",
    "\n",
    "# The \"street\" is defined by: w·x + b = 0\n",
    "print(f\"Support vectors: {model.support_vectors_}\")\n",
    "print(f\"Number of support vectors: {len(model.support_vectors_)}\")\n",
    "\n",
    "```\n",
    "\n",
    "The Math Behind It:\n",
    "\n",
    "``` bash\n",
    "Minimize: ½||w||²  (makes the street wide)\n",
    "Subject to: yᵢ(w·xᵢ + b) ≥ 1  (all points correctly classified)\n",
    "\n",
    "```\n",
    "Where:\n",
    "\n",
    "w = perpendicular to the decision boundary\n",
    "\n",
    "||w|| = width of the margin (smaller w = wider street)\n",
    "\n",
    "Points with yᵢ(w·xᵢ + b) = 1 are support vectors\n",
    "\n",
    "\n",
    "\n",
    "The Magic Trick: Kernel Method\n",
    "Problem: Real data isn't always linearly separable in 2D.\n",
    "\n",
    "SVC's solution: \"Let's look at it from a different angle!\"\n",
    "```bash\n",
    " Before kernel trick (can't separate circles):\n",
    " • • •   • • •\n",
    " • • •   • • •\n",
    " • • •   • • •\n",
    "\n",
    " With kernel trick (project to 3D, now separable):\n",
    "    • • •           (higher up)\n",
    "   • • •           (middle height)\n",
    "  • • •           (lower down)\n",
    "\n",
    "\n",
    "```\n",
    "Common Kernels:\n",
    "```bash\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Linear Kernel (for linearly separable data)\n",
    "svc_linear = SVC(kernel='linear')\n",
    "\n",
    "# 2. Polynomial Kernel (for curved boundaries)\n",
    "svc_poly = SVC(kernel='poly', degree=3)  # Degree controls curvature\n",
    "\n",
    "# 3. RBF (Radial Basis Function) Kernel - MOST COMMON\n",
    "#    Creates circular/oval boundaries, flexible\n",
    "svc_rbf = SVC(kernel='rbf', gamma='scale')\n",
    "\n",
    "# 4. Sigmoid Kernel (similar to neural network)\n",
    "svc_sigmoid = SVC(kernel='sigmoid')\n",
    "```\n",
    "\n",
    "\n",
    "### When to Use SVC:\n",
    " GOOD For:\n",
    "Small to medium datasets (scales poorly with huge data)\n",
    "\n",
    "High-dimensional data (text, images, genes - where features > samples)\n",
    "\n",
    "Clear margin of separation expected\n",
    "\n",
    "Binary classification problems\n",
    "\n",
    "When you need a robust boundary (less affected by outliers than other methods)\n",
    "\n",
    " BAD For:\n",
    "Very large datasets (slow training time, O(n²) to O(n³))\n",
    "\n",
    "Noisy data with overlapping classes (performs poorly)\n",
    "\n",
    "Multi-class problems (though sklearn handles it with \"one-vs-one\")\n",
    "\n",
    "When you need probability estimates (SVC doesn't naturally provide them)\n",
    "\n",
    "When interpretability is crucial (hard to explain kernel transformations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
