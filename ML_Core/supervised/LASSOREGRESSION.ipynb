{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11da07a6",
   "metadata": {},
   "source": [
    "# LASSO REGRESSION (L1 REGULARIZATION)\n",
    "```\n",
    "LASSO = Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "It is a linear regression technique that adds L1 penalty to reduce overfitting and perform feature selection.\n",
    "\n",
    "```\n",
    "\n",
    "Lasso modifies the linear regression loss like this:\n",
    " \n",
    "Cost = ∑ (yi​−y^​i​)^ 2 /  λ ∑ |βj​|\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "λ (lambda) = regularization strength\n",
    "\n",
    "L1 penalty = sum of absolute values of coefficients\n",
    "\n",
    "#### Why use Lasso Regression?\n",
    "\n",
    "Because Lasso can:\n",
    "\n",
    "1. Reduce overfitting (regularization)\n",
    "2. Select features automatically (important!)\n",
    "\n",
    "Some coefficients become exactly zero\n",
    "\n",
    "So it removes unimportant features\n",
    "\n",
    "This makes Lasso useful when:\n",
    "\n",
    "You have many features\n",
    "\n",
    "You don’t know which features matter\n",
    "\n",
    "You want a simpler, interpretable model\n",
    "\n",
    "\n",
    "#### How Lasso works \n",
    "\n",
    "The L1 penalty creates a diamond-shaped constraint.\n",
    "The regression loss is an ellipse.\n",
    "\n",
    "When the ellipse touches the diamond corners, the model sets coefficients to exactly 0.\n",
    "\n",
    "This is why Lasso performs feature selection and Ridge does not.\n",
    "\n",
    "#### Mathematical Solution\n",
    "\n",
    "There is no closed-form solution for Lasso like Ridge.\n",
    "\n",
    "We use optimization methods:\n",
    "\n",
    "Coordinate descent\n",
    "\n",
    "Subgradient methods\n",
    "\n",
    "LARS (Least Angle Regression)\n",
    "\n",
    "\n",
    "#### Effect of λ (lambda)\n",
    "λ Value\t    Effect\n",
    "0\t        Same as Linear Regression\n",
    "Small\t    Slight shrinkage\n",
    "Larger\t    Many coefficients → 0\n",
    "Very large\tUnderfitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Lasso vs Ridge Regression\n",
    "\n",
    "\n",
    "\n",
    "Feature\t              Lasso\t            Ridge\n",
    "Penalty\t              L1\t            L2\n",
    "Coefficients          Some become 0\t    Shrinks but never 0\n",
    "Feature Selection\t  Yes\t            No\n",
    "Good for\t          Sparse models\t    Multicollinearity\n",
    "Coefficient stability Can be unstable\tStable\n",
    "\n",
    "\n",
    "\n",
    "When to use\tFew important features\tMany small effects\n",
    "\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "Performs automatic feature selection\n",
    "\n",
    "Reduces overfitting\n",
    "\n",
    "Improves model interpretability\n",
    "\n",
    "Best for high-dimensional data (p >> n)\n",
    "\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "When features are highly correlated, Lasso picks one and ignores others\n",
    "\n",
    "Coefficients can be unstable\n",
    "\n",
    "Not ideal when all features are important\n",
    "\n",
    "#### When to use Lasso Regression?\n",
    "\n",
    "Use Lasso when:\n",
    "\n",
    " Want feature selection\n",
    " Have many irrelevant features\n",
    " Need a simple model\n",
    " Working with high-dimensional dataset\n",
    " Features are not strongly correlated\n",
    "\n",
    "\n",
    "\n",
    "``` \n",
    "Lasso uses L1 regularization\n",
    "\n",
    "Reduces overfitting\n",
    "\n",
    "Makes some coefficients exactly zero\n",
    "\n",
    "Performs feature selection\n",
    "\n",
    "Good for high-dimensional data\n",
    "\n",
    "λ controls strength of regularization\n",
    "\n",
    "Solved using optimization (no closed-form solution)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5734a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 3.92693362e-01  1.50810624e-02 -0.00000000e+00  0.00000000e+00\n",
      "  1.64168387e-05 -3.14918929e-03 -1.14291203e-01 -9.93076483e-02]\n",
      "Intercept: -7.698845419807455\n",
      "MSE: 0.6135115198058131\n",
      "R2 Score: 0.5318167610318159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Lasso model\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"MSE:\", mean_squared_error(Y_test, y_pred))\n",
    "print(\"R2 Score:\", r2_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87b679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [   0.         -152.66477923  552.69777529  303.36515791  -81.36500664\n",
      "   -0.         -229.25577639    0.          447.91952518   29.64261704]\n",
      "Intercept: 151.57485282893947\n",
      "MSE: 2798.193485169719\n",
      "R2 Score: 0.4718547867276227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"MSE:\", mean_squared_error(Y_test, y_pred))\n",
    "print(\"R2 Score:\", r2_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f112eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [41.82204111 64.12395241 18.73201774 46.72243239 23.9565675  16.39228576\n",
      " 82.69535426 64.17889918  7.4871428  28.65860581]\n",
      "Intercept: -0.2927999172299187\n",
      "MSE: 97.1743302138308\n",
      "R2 Score: 0.9950667951885857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Synthetic regression dataset\n",
    "X, y = make_regression(\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    noise=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"MSE:\", mean_squared_error(Y_test, y_pred))\n",
    "print(\"R2 Score:\", r2_score(Y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
